{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> FlyWave Classification Notebook </h1>\n",
    "\n",
    "A quick tutorial on how to setup and run a deep learning classifier using Keras for Hand Gesture classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATAPATH = 'images/'\n",
    "HEIGHT = 360\n",
    "WIDTH = 640\n",
    "# input image dimensions\n",
    "img_rows, img_cols = HEIGHT, WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place preprocessing methods into this method. We will use this to return a modified version of the image so that we can add them to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    img = cv2.resize(img, (img.shape[0]//2, img.shape[1]//2))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from the \"images\" directory by reading in the images. We can resize the images to half their width and height since we don't need all of the color data (nor do we want our model to take forever to train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "label_index = 0 \n",
    "\n",
    "for label in os.listdir(DATAPATH):\n",
    "    if label == 'ok' or label == 'rock':\n",
    "        img_dir = DATAPATH + label + '/'\n",
    "        for fn in os.listdir(img_dir):\n",
    "            img = cv2.imread(img_dir + fn, 1)\n",
    "            img = preprocess(img)\n",
    "            data.append(img)\n",
    "            labels.append(label_index)\n",
    "        label_index += 1    \n",
    "\n",
    "print(\"Finished loading data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the data into numpy arrays to input into our model, and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('data.npy', data)\n",
    "np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use these to load your data\n",
    "data = np.load('data.npy')\n",
    "labels = np.load('labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition the data into our training set and test set. We usually use 80% of our data to train our model on and 20% of our data to test it on, so we don't over fit our model. SKLearn has a handy function for doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to set up our data to put into our Keras model. We set the parameters in this cell (batch size, epochs, etc) and also normalize the image data so that we have data from [0,255] to [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (400, 720, 1280, 3)\n",
      "400 train samples\n",
      "100 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 12\n",
    "channels = 3\n",
    "\n",
    "\n",
    "# the data, split between train and test sets\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], channels, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], channels, img_rows, img_cols)\n",
    "    input_shape = (channels, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, channels)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, channels)\n",
    "    input_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Model</h3>\n",
    "\n",
    "\n",
    "We can now create our neural network model. In Keras, we initialize a sequence of neural network layers with Sequential(). Once we have our base model, we can then simply add our desired layers. Keras provides a handful of methods that we can add to our model, which include:\n",
    "\n",
    "Conv2D(# hidden units, kernel_size, activation, input_shape)\n",
    "MaxPooling2D(pool_size)\n",
    "Dropout\n",
    "Flatten\n",
    "Dense(# hidden units, activation)\n",
    "\n",
    "Any of these layers can be added in any combination with model.add(LAYER). \n",
    "\n",
    "<b>Activation Functions</b> <br>\n",
    "softmax - map hidden units to probabilities [0,1]\n",
    "relu - useful for images in convolutional layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Conv2D (32 hidden layers, kernel=[3,3]) -> relu -> #Conv2D (32 hidden layers, kernel=[3,3]) -> relu ->\n",
    "#maxpooling (2,2) -> dropout -> flatten (change from 3D to 1D) -> fully connected layer (128 hidden layers) -> relu -> \n",
    "#dropout -> Classification using softmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Validation and Model Evaluation</h3>\n",
    "\n",
    "Once the model is complete, we can compile it by specifying the necessary parameters. Loss specifies what loss function the model is trying to minimize. The optimizer is the algorithm that is used to lower the loss. \n",
    "\n",
    "\n",
    "You can now train the model by calling the \"fit\" method. Now watch your model train and see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/12\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"results.txt\", \"w\") as f:\n",
    "    f.write(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"model_0.h5\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [MLKart]",
   "language": "python",
   "name": "Python [MLKart]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
